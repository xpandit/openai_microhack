{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Walkthrough Challenge 4 - Chat with your own data\n",
    "\n",
    "Duration: 30 minutes\n",
    "\n",
    "## Overview\n",
    "- In this challenge, you will learn on how to use the `Chat` api to keep history of the conversation within a chatbot.\n",
    "- You will also learn to implement the *Retrieval Augmented Generation* (RAG) architecture to chat with your own data.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Please ensure that you have completed the [Setup](../setup/setup.ipynb) before starting this challenge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Configure and Initialize Semantic Kernel\n",
    "\n",
    "‚ö†Ô∏è Note: You should have already completed all tasks on the [Setup](../setup/setup.ipynb). If you have not, please go back and complete it now.\n",
    "\n",
    "#### Step 1: Load Semantic Kernel settings\n",
    "\n",
    "In this step, we will load the Semantic Kernel settings that we created in the [Setup](../setup/setup.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Microsoft.KernelMemory.Core, 0.26.240121.1</span></li><li><span>Microsoft.KernelMemory.SemanticKernelPlugin, 0.26.240121.1</span></li><li><span>Microsoft.SemanticKernel, 1.0.1</span></li><li><span>Microsoft.SemanticKernel.Connectors.Sqlite, 1.0.1-alpha</span></li><li><span>Microsoft.SemanticKernel.Planners.Handlebars, 1.0.1-preview</span></li><li><span>Microsoft.SemanticKernel.Planners.OpenAI, 1.0.1-preview</span></li><li><span>Microsoft.SemanticKernel.Plugins.Memory, 1.0.1-alpha</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r \"nuget: Microsoft.SemanticKernel, 1.0.1\"\n",
    "#r \"nuget: Microsoft.SemanticKernel.Planners.Handlebars, 1.0.1-preview\"\n",
    "#r \"nuget: Microsoft.SemanticKernel.Planners.OpenAI, 1.0.1-preview\"\n",
    "#r \"nuget: Microsoft.SemanticKernel.Plugins.Memory, 1.0.1-alpha\"\n",
    "#r \"nuget: Microsoft.SemanticKernel.Connectors.Sqlite, 1.0.1-alpha\"\n",
    "#r \"nuget: Microsoft.KernelMemory.Core, 0.26.240121.1\"\n",
    "#r \"nuget: Microsoft.KernelMemory.SemanticKernelPlugin, 0.26.240121.1\"\n",
    "\n",
    "#!import ../setup/config/Settings.cs\n",
    "#!import ../setup/config/Utils.cs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Initialize Semantic Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "using Microsoft.SemanticKernel;\n",
    "using Microsoft.SemanticKernel.Connectors.OpenAI;\n",
    "using Microsoft.SemanticKernel.TemplateEngine;\n",
    "using Microsoft.SemanticKernel.ChatCompletion;\n",
    "using Microsoft.SemanticKernel.Connectors.Sqlite;\n",
    "using Microsoft.SemanticKernel.Memory;\n",
    "using Microsoft.SemanticKernel.Plugins.Memory;\n",
    "using Microsoft.KernelMemory;\n",
    "using Kernel = Microsoft.SemanticKernel.Kernel;\n",
    "using Microsoft.DotNet.Interactive;\n",
    "using InteractiveKernel = Microsoft.DotNet.Interactive.Kernel;\n",
    "\n",
    "var builder = Kernel.CreateBuilder();\n",
    "\n",
    "// Configure AI service credentials used by the kernel\n",
    "var (useAzureOpenAI, model, azureEndpoint, apiKey, orgId) = Settings.LoadFromFile(\"../setup/config/settings.json\");\n",
    "\n",
    "if (useAzureOpenAI)\n",
    "    builder.AddAzureOpenAIChatCompletion(model, azureEndpoint, apiKey);\n",
    "else\n",
    "    builder.AddOpenAIChatCompletion(model, apiKey, orgId);\n",
    "\n",
    "var kernel = builder.Build();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Create a chatbot like experience, mainting the context of the conversation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by creating a `ChatHistory` object to maintain the context of the conversation. This object will be used to store the conversation history, namely the system prompts, user inputs and the assistant responses.\n",
    "\n",
    "The `ChatHistory` object will be initialized with the system prompt.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "var chatHistory = new ChatHistory(\"You are an historian, expert in the Seven Wonders of the Ancient World. Be concise and informative.\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `MessageOutputAsync` method will allow us to print the latest message from the chat history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system: You are an historian, expert in the Seven Wonders of the Ancient World. Be concise and informative.\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "await Utils.MessageOutputAsync(chatHistory);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To interact with the chatbot, we will require the `ChatCompletionService`. This will be used to interact with the Large Language Model to generate responses to the user inputs.\n",
    "\n",
    "After adding the user input to the chat history, we will use the `ChatCompletionService` to generate a response. This response will be added to the chat history and printed to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "ename": "Error",
     "evalue": "(11,7): error CS0103: The name 'MessageOutputAsync' does not exist in the current context\n(19,7): error CS0103: The name 'MessageOutputAsync' does not exist in the current context",
     "output_type": "error",
     "traceback": [
      "(11,7): error CS0103: The name 'MessageOutputAsync' does not exist in the current context\n",
      "(19,7): error CS0103: The name 'MessageOutputAsync' does not exist in the current context"
     ]
    }
   ],
   "source": [
    "var chatCompletionService = kernel.GetRequiredService<IChatCompletionService>();\n",
    "\n",
    "var executionSettings = new OpenAIPromptExecutionSettings\n",
    "{\n",
    "    MaxTokens = 500,\n",
    "    Temperature = 0.2,\n",
    "    TopP = 0.5\n",
    "};\n",
    "\n",
    "chatHistory.AddUserMessage(\"Hi, what is the Great Pyramid of Giza?\");\n",
    "await Utils.MessageOutputAsync(chatHistory);\n",
    "\n",
    "var reply = await chatCompletionService.GetChatMessageContentAsync(\n",
    "        chatHistory,\n",
    "        executionSettings: executionSettings,\n",
    "        kernel: kernel);\n",
    "\n",
    "chatHistory.Add(reply);\n",
    "await Utils.MessageOutputAsync(chatHistory);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add the new message to chat history. You will see that the chat model will use the context of the conversation to generate a response.\n",
    "\n",
    "Take note that chat history counts towards your token usage, so be mindful of the number of messages you send. Strategies such as counting the number of tokens and truncating the history to only include the last few messages can be used to manage token usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "ename": "Error",
     "evalue": "(4,19): error CS0103: The name 'chatCompletionService' does not exist in the current context\n(6,28): error CS0103: The name 'executionSettings' does not exist in the current context\n(2,7): error CS0103: The name 'MessageOutputAsync' does not exist in the current context\n(10,7): error CS0103: The name 'MessageOutputAsync' does not exist in the current context",
     "output_type": "error",
     "traceback": [
      "(4,19): error CS0103: The name 'chatCompletionService' does not exist in the current context\n",
      "(6,28): error CS0103: The name 'executionSettings' does not exist in the current context\n",
      "(2,7): error CS0103: The name 'MessageOutputAsync' does not exist in the current context\n",
      "(10,7): error CS0103: The name 'MessageOutputAsync' does not exist in the current context"
     ]
    }
   ],
   "source": [
    "chatHistory.AddUserMessage(\"And do you know who built it?\");\n",
    "await Utils.MessageOutputAsync(chatHistory);\n",
    "\n",
    "var reply = await chatCompletionService.GetChatMessageContentAsync(\n",
    "        chatHistory,\n",
    "        executionSettings: executionSettings,\n",
    "        kernel: kernel);\n",
    "\n",
    "chatHistory.Add(reply);\n",
    "await Utils.MessageOutputAsync(chatHistory);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can experiment interacting with the chatbot by adding more messages to the chat history and observing the responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "ename": "Error",
     "evalue": "(7,15): error CS0103: The name 'MessageOutputAsync' does not exist in the current context\n(9,27): error CS0103: The name 'chatCompletionService' does not exist in the current context\n(11,36): error CS0103: The name 'executionSettings' does not exist in the current context\n(15,15): error CS0103: The name 'MessageOutputAsync' does not exist in the current context",
     "output_type": "error",
     "traceback": [
      "(7,15): error CS0103: The name 'MessageOutputAsync' does not exist in the current context\n",
      "(9,27): error CS0103: The name 'chatCompletionService' does not exist in the current context\n",
      "(11,36): error CS0103: The name 'executionSettings' does not exist in the current context\n",
      "(15,15): error CS0103: The name 'MessageOutputAsync' does not exist in the current context"
     ]
    }
   ],
   "source": [
    "do\n",
    "{\n",
    "    try\n",
    "    {\n",
    "        var ask = await InteractiveKernel.GetInputAsync(\"Ask a question to the assistant: \");\n",
    "        chatHistory.AddUserMessage(ask);\n",
    "        await Utils.MessageOutputAsync(chatHistory);\n",
    "\n",
    "        var reply = await chatCompletionService.GetChatMessageContentAsync(\n",
    "                chatHistory,\n",
    "                executionSettings: executionSettings,\n",
    "                kernel: kernel);\n",
    "\n",
    "        chatHistory.Add(reply);\n",
    "        await Utils.MessageOutputAsync(chatHistory);\n",
    "    }\n",
    "    catch (Exception)\n",
    "    {\n",
    "        // break the loop if the user cancels the input\n",
    "        break;\n",
    "    }\n",
    "} while (true);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Use your own data to chat with the model\n",
    "\n",
    "In some scenarions, you may want the model to respond with specific information based on your own data. For example, you may have internal documentation about an appliance, and the model should respond with information that is specific to that appliance, not from the general knowledge it has been trained on.\n",
    "\n",
    "This approach is called *Retrieval Augmented Generation* (RAG). In this approach, the model first retrieves relevant information from a knowledge source, and then generates a response based on the retrieved information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "var memorybuilder = new KernelMemoryBuilder();\n",
    "\n",
    "memorybuilder.WithAzureOpenAITextEmbeddingGeneration(new AzureOpenAIConfig()\n",
    "{\n",
    "    Auth = AzureOpenAIConfig.AuthTypes.APIKey,\n",
    "    APIKey = apiKey,\n",
    "    APIType = AzureOpenAIConfig.APITypes.EmbeddingGeneration,\n",
    "    Endpoint = azureEndpoint,\n",
    "    Deployment = \"Text-embedding-ada-002\"\n",
    "});\n",
    "\n",
    "memorybuilder.WithAzureOpenAITextGeneration(new AzureOpenAIConfig()\n",
    "{\n",
    "    Auth = AzureOpenAIConfig.AuthTypes.APIKey,\n",
    "    APIKey = apiKey,\n",
    "    APIType = AzureOpenAIConfig.APITypes.ChatCompletion,\n",
    "    Endpoint = azureEndpoint,\n",
    "    Deployment = model\n",
    "});\n",
    "\n",
    "var memory = memorybuilder.Build();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by importing a document about Germany Labour Law using the *Semantic Memory* library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "await memory.ImportWebPageAsync(\n",
    "    \"https://www.ilo.org/ifpdial/information-resources/national-labour-law-profiles/WCMS_158899/lang--en/index.htm\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we can import the *Semantic Memory* library and use it to add the document to the knowledge base. We will do it via the `MemoryPlugin` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "using Microsoft.KernelMemory;\n",
    "\n",
    "var memoryPlugin = kernel.ImportPluginFromObject(new MemoryPlugin(memory));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a prompt representig the Retrieval Augmented Generation (RAG) approach. The prompt will have an input variable that will represent the user question and will have a function call to the `MemoryPlugin` to retrieve the relevant information from the knowledge base, using the `ask` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "var skPrompt = \"\"\"\n",
    "Question to Memory: {{$input}}\n",
    "\n",
    "Answer from Memory: {{MemoryPlugin.Ask $input}}\n",
    "\n",
    "If the answer is empty say 'I don't know' otherwise reply with a preview of the answer,\n",
    "truncated to 15 words. Prefix with one emoji relevant to the content.\n",
    "\"\"\";\n",
    "\n",
    "var ragFunction = kernel.CreateFunctionFromPrompt(skPrompt);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we're ready to use the RAG approach to chat with the model. Let's ask a question about Germany Labour Law and see how the model responds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèñÔ∏è In Germany, the statutory minimum leave entitlement is 24 days per calendar year, not counting Sundays...\n"
     ]
    }
   ],
   "source": [
    "var answer = await ragFunction.InvokeAsync(kernel, \"How many vacations days do I get in Germany?\");\n",
    "\n",
    "Console.WriteLine(answer);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to test the case when the model does not have the information, let's ask a question about Portugal Labour Law."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèñÔ∏è In Portugal, the minimum vacation entitlement is 22 working days per year for a full-time...\n"
     ]
    }
   ],
   "source": [
    "var answer = await ragFunction.InvokeAsync(kernel, \"How many vacations days do I get in Portugal?\");\n",
    "\n",
    "Console.WriteLine(answer);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You successfully completed challenge 4! üöÄüöÄüöÄ\n",
    "\n",
    " **[Home](../../Readme.md)**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
